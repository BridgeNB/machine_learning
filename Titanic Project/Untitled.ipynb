{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "titanic = pandas.read_csv(\"data/train.csv\")\n",
    "print (titanic.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  891.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.361582    0.523008   \n",
      "std     257.353842    0.486592    0.836071   13.019697    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   22.000000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   35.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n"
     ]
    }
   ],
   "source": [
    "titanic[\"Age\"] = titanic[\"Age\"].fillna(titanic[\"Age\"].median())\n",
    "print (titanic.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male' 'female']\n"
     ]
    }
   ],
   "source": [
    "print (titanic[\"Sex\"].unique())\n",
    "\n",
    "# Replace all the orrurences of male with the number 0\n",
    "titanic.loc[titanic[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "titanic.loc[titanic[\"Sex\"] == \"female\", \"Sex\"] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S' 'C' 'Q' nan]\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name Sex   Age  SibSp  Parch  \\\n",
      "0                            Braund, Mr. Owen Harris   0  22.0      1      0   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...   1  38.0      1      0   \n",
      "2                             Heikkinen, Miss. Laina   1  26.0      0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)   1  35.0      1      0   \n",
      "4                           Allen, Mr. William Henry   0  35.0      0      0   \n",
      "\n",
      "             Ticket     Fare Cabin Embarked  \n",
      "0         A/5 21171   7.2500   NaN        0  \n",
      "1          PC 17599  71.2833   C85        1  \n",
      "2  STON/O2. 3101282   7.9250   NaN        0  \n",
      "3            113803  53.1000  C123        0  \n",
      "4            373450   8.0500   NaN        0  \n"
     ]
    }
   ],
   "source": [
    "print (titanic[\"Embarked\"].unique())\n",
    "titanic[\"Embarked\"] = titanic[\"Embarked\"].fillna('S')\n",
    "titanic.loc[titanic[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "titanic.loc[titanic[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "titanic.loc[titanic[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n",
    "print(titanic.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import the linear regression class\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Sklearn also has a helper that makes it easy to do cross validation\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "# The columns use to predict the target\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "# Initialize our algorithm class\n",
    "alg = LinearRegression()\n",
    "# Generate cross validation folds for the titanic dataset\n",
    "# set_random_state to ensure we get the same splits every time we run it\n",
    "kf = KFold(titanic.shape[0], n_folds=3, random_state = 1)\n",
    "# kf = KFold(n_splits=2)\n",
    "# help(KFold)\n",
    "\n",
    "predictions= []\n",
    "\n",
    "for train, test in kf:\n",
    "        # The predictors we are using the train the algorithm\n",
    "        train_predictors = (titanic[predictors].iloc[train, :])\n",
    "        # The target we are using to train the algorithm\n",
    "        train_target = titanic[\"Survived\"].iloc[train]\n",
    "        # Training the algorithm using the predictors and target\n",
    "        alg.fit(train_predictors, train_target)\n",
    "        # We can now make predictions on the test fold\n",
    "        test_predictions = alg.predict(titanic[predictors].iloc[test, :])\n",
    "        predictions.append(test_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.383838383838\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# The predictions are in three separate numpy arrays. Concatenate them into one\n",
    "predictions = np.concatenate(predictions, axis = 0)\n",
    "\n",
    "# Map predictions to outcomes (only possible outcomes are 1 and 0)\n",
    "predictions[predictions > .5] = 1\n",
    "predictions[predictions <= .5] = 0\n",
    "accuracy = sum(predictions[predictions == titanic[\"Survived\"]]) / len(predictions)\n",
    "print (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.787878787879\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Initialize our algorithm\n",
    "alg = LogisticRegression(random_state = 1)\n",
    "# Compute the accuracy score for all the cross validation folds\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv = 3)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test data clean up\n",
    "titanic_test = pandas.read_csv(\"data/test.csv\")\n",
    "titanic_test[\"Age\"] = titanic[\"Age\"].fillna(titanic[\"Age\"].median())\n",
    "titanic_test[\"Fare\"] = titanic[\"Fare\"].fillna(titanic[\"Fare\"].median())\n",
    "titanic_test.loc[titanic[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "titanic_test.loc[titanic[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "\n",
    "titanic_test[\"Embarked\"] = titanic_test[\"Embarked\"].fillna(\"S\")\n",
    "titanic_test.loc[titanic[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "titanic_test.loc[titanic[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "titanic_test.loc[titanic[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.785634118967\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "# Initialize our algorithm with the default parameters\n",
    "# the number of trees we want to make                     --      n_estimators\n",
    "# the minimum number of rows to split                     --      min_samples_split\n",
    "# the minimum number of samples when a tree branch ends   --      min_samples_leaf\n",
    "alg = RandomForestClassifier(random_state = 1, n_estimators = 10, min_samples_split = 2, min_samples_leaf = 1)\n",
    "# Compute the accuracy score for all the cross validation folds\n",
    "kf = cross_validation.KFold(titanic.shape[0], n_folds = 3, random_state = 1)\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv = kf)\n",
    "\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81593714927\n"
     ]
    }
   ],
   "source": [
    "# After adjusting random forest parameters\n",
    "# Several scnerios to prevent like - set the tree too high to overfit\n",
    "alg = RandomForestClassifier(random_state = 1, n_estimators = 50, min_samples_split = 4, min_samples_leaf = 2)\n",
    "# Compute the accuracy score for all the cross validation folds\n",
    "kf = cross_validation.KFold(titanic.shape[0], n_folds = 3, random_state = 1)\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv = kf)\n",
    "\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# More improvements on adding more features\n",
    "titanic[\"FamilySize\"] = titanic[\"SibSp\"] + titanic[\"Parch\"]\n",
    "\n",
    "# The apply method generates a new series\n",
    "titanic[\"NameLength\"] = titanic[\"Name\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mr.          517\n",
      " Miss.        182\n",
      " Mrs.         125\n",
      " Master.       40\n",
      " Dr.            7\n",
      " Rev.           6\n",
      " Mlle.          2\n",
      " Col.           2\n",
      " Major.         2\n",
      " Ms.            1\n",
      " Capt.          1\n",
      " Sir.           1\n",
      " Mme.           1\n",
      " Jonkheer.      1\n",
      " Lady.          1\n",
      " Countess.      1\n",
      " Don.           1\n",
      "Name: Name, dtype: int64\n",
      "1     517\n",
      "2     182\n",
      "3     125\n",
      "4      40\n",
      "5       7\n",
      "6       6\n",
      "8       2\n",
      "7       2\n",
      "9       2\n",
      "16      1\n",
      "10      1\n",
      "11      1\n",
      "12      1\n",
      "13      1\n",
      "14      1\n",
      "15      1\n",
      "17      1\n",
      "Name: Name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# A function to get the title from a name\n",
    "def get_title(name):\n",
    "    # Use a regular expression to search for a title.\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it\n",
    "    if title_search:\n",
    "        return title_search.group()\n",
    "    return \"\"\n",
    "\n",
    "# Extract all the titles and print how often each one occurs\n",
    "titles = titanic[\"Name\"].apply(get_title)\n",
    "\n",
    "print(pandas.value_counts(titles))\n",
    "\n",
    "# Map title with maps\n",
    "title_mapping = {\" Mr.\": 1, \" Miss.\": 2, \" Mrs.\": 3, \" Master.\": 4, \" Dr.\": 5, \" Rev.\": 6, \" Major.\": 7, \" Col.\": 8, \" Mlle.\": 9, \" Jonkheer.\": 10, \" Lady.\": 11, \" Mme.\": 12, \" Countess.\": 13, \" Capt.\": 14, \" Ms.\": 15, \" Don.\": 16, \" Sir.\": 17}\n",
    "for k, v in title_mapping.items():\n",
    "    titles[titles.replace(\" \", \"\") == k] = v\n",
    "\n",
    "print(pandas.value_counts(titles))\n",
    "\n",
    "# Add titles to titanic column\n",
    "titanic[\"Title\"] = titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEyCAYAAADqYisiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP5HXWKua5S3SAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c74ef98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature importance analysis\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"NameLength\"]\n",
    "\n",
    "# Perform feature selection\n",
    "selector = SelectKBest(f_classif, k ='all')\n",
    "selector.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "\n",
    "# GEt the raw p-value for each feature, and transform from p-value into scores\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "\n",
    "# Plot the scores and exam the importance of \"Pclass\", \"Sex\", \"Fare\"\n",
    "plt.bar(range(len(predictors)), scores)\n",
    "plt.xticks(range(len(predictors)), predictors, rotation='vertical')\n",
    "plt.show()\n",
    "\n",
    "# Pick only the four best features\n",
    "predictors = [\"Pclass\", \"Sex\", \"Fare\", \"Title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27721661055\n"
     ]
    }
   ],
   "source": [
    "# Ensemble multiple classifier to evaluate performamce \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "\n",
    "# The algorithm we want to ensemble\n",
    "# We're using the more linear predictors for the logistic regression\n",
    "#                 random predictors for the gradient boosting classifier\n",
    "algorithms = [\n",
    "    [GradientBoostingClassifier(random_state = 1, n_estimators = 25, max_depth=3), [\"Pclass\", \"Sex\", \"Fare\", \"FamilySize\", \"Title\", \"Age\", \"Embarked\"]],\n",
    "    [LogisticRegression(random_state = 1), [\"Pclass\", \"Sex\", \"Fare\", \"FamilySize\", \"Title\", \"Age\", \"Embarked\"]]\n",
    "]\n",
    "\n",
    "# Initialize the cross validation folds\n",
    "kf = KFold(titanic.shape[0], n_folds=3, random_state = 1)\n",
    "\n",
    "predictions = []\n",
    "for train, test in kf:\n",
    "    train_target = titanic[\"Survived\"].iloc[train]\n",
    "    full_test_predictions = []\n",
    "    # Make predictions for each algorithm on each fold\n",
    "    for alg, predictors in algorithms:\n",
    "        # Fit the algorithm on the training data\n",
    "        alg.fit(titanic[predictors].iloc[train, :], train_target)\n",
    "        # Select and predict on the test fold\n",
    "        # the .astype(float) is necessary to convert the dataframe to all floats and avoid an sklearn error\n",
    "        test_predictions = alg.predict_proba(titanic[predictors].iloc[test, :].astype(float))[:,1]\n",
    "        full_test_predictions.append(test_predictions)\n",
    "    # Use a simple ensembling scheme -- just average the predictions to get the final classification\n",
    "    test_predictions = (full_test_predictions[0] + full_test_predictions[1]) / 2\n",
    "    # Any value over .5 is assumed to be a 1 prediction, and below .5 is a 0 prediction\n",
    "    test_predictions[test_predictions <= .5] = 0\n",
    "    test_predictions[test_predictions > .5] = 1\n",
    "    predictions.append(test_predictions)\n",
    "    \n",
    "# Summize all predictions results\n",
    "predictions = np.concatenate(predictions, axis = 0)\n",
    "\n",
    "# Compute accuracy by comparing to the training data\n",
    "accuracy = sum(predictions[predictions == titanic[\"Survived\"]]) / len(predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
